# ğŸŒ¾ Crop Monitoring Data Pipeline

> A scalable and optimized geospatial data pipeline using Apache Spark (with Sedona), Iceberg, Docker, Airflow, and AWS S3 (or MinIO). Designed for efficient crop monitoring via LST, GDD, and Sentinel-2 indices.

---

## ğŸ§© Overview

This project is designed to:

1. Retrieve **polygon boundaries** from a PostgreSQL database.
2. Fetch **Land Surface Temperature (LST)** data from the Visual Crossing API.
3. Calculate **Growing Degree Days (GDD)** for crop stage estimation.
4. Query **Sentinel-2 indices** (e.g., NDVI, NDWI) via CropHelp API based on crop stages.
5. Store all results in **Iceberg tables** for scalable analytics.
6. Orchestrate the workflow using **Apache Airflow**.
7. Containerized with **Docker Compose** for easy deployment and scaling.

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|------|---------|
| **PySpark + Sedona** | Distributed processing of geospatial data |
| **Iceberg** | High-performance table format stored in S3/MinIO |
| **Airflow** | Workflow orchestration and scheduling |
| **PostgreSQL** | Source of polygon and metadata |
| **MinIO** | Local S3-compatible storage (dev/test alternative to AWS S3) |
| **Docker / Docker Compose** | Containerization and service orchestration |

---

## ğŸ“ Project Structure

crop_monitoring_pipeline/
â”‚
â”œâ”€â”€ docker-compose.yaml # Main orchestration file
â”‚
â”œâ”€â”€ spark/
â”‚ â”œâ”€â”€ jobs/ # PySpark scripts
â”‚ â”œâ”€â”€ Dockerfile # Spark image with Sedona & Iceberg
â”‚ â””â”€â”€ requirements.txt # Python dependencies for Spark jobs
â”‚
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/ # Airflow DAGs
â”‚ â””â”€â”€ requirements.txt # Extra providers/plugins for Airflow
â”‚
â”œâ”€â”€ python_scripts/
â”‚ â”œâ”€â”€ api_calls/ # Non-Spark scripts (e.g., API calls)
â”‚ â””â”€â”€ utils/ # Helper functions
â”‚
â”œâ”€â”€ postgres/
â”‚ â””â”€â”€ init.sql # Optional DB setup script
â”‚
â”œâ”€â”€ minio/ # Optional local S3 emulation
â”‚
â””â”€â”€ README.md # This file


---

## ğŸš€ Getting Started

### Prerequisites

- Docker Desktop installed
- Basic understanding of Docker, Spark, and Airflow

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/agri-pipeline.git 
cd crop_monitoring_pipeline
